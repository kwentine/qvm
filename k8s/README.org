#+TITLE: Kubernetes, the vanilla way

Document experiments performed on a cluster stetup following [[https://github.com/kelseyhightower/kubernetes-the-hard-way][Kubernetes the Hard Way]].

* In

- Uninstall =cockpit= and =insights-client= since they are not needed and output annoying =/etc/motd.d=
#+begin_src sh
  for host in cp wk1 wk2; do
    ssh -T root@"${host}" dnf -y remove cockpit-ws-334.1-1.el10_0.x86_64 insights-client
  done
#+end_src

- Verify that I can connect to the API server from my host.
  The CA  used to authenticate the certificate presented by the server is embedded in the varioud =.kubeconfig= files
#+begin_src sh
  openssl s_client -showcerts -connect cp.qvm0.lan:6443 -verifyCAfile /var/vms/certs/k8s/ca.crt  </dev/null
    | openssl x509 -noout -text
#+end_src

- Examine the TLS identity that the =admin= user presents to the API server:
#+begin_example
$ yq '.users[0].user.client-certificate-data' admin.kubeconfig | base64 -d | openssl x509 -noout -subject
subject=CN=admin, O=system:masters
#+end_example

* User credentials and RBAC
** Client certificate
Certificates used for client authentication must be issued by CA the API server trusts.
This is the =--client-ca-file= flag:
#+begin_example
kube-apiserver --client-ca-file=/var/lib/kubernetes/ca.crt #...
#+end_example

I keep this CA certificate and corresponding key in =$QVM_DIR/certs/k8s/ca.{key,crt}=

Create a certificate for user =kwentine=, and verify that it can be used to authenticate:
#+begin_example
$ ./create_user_cert.sh kwentine
$ curl --cert kwentine.crt --key kwentine.key \
     --cacert /var/vms/certs/k8s/ca.crt \
     --json {"apiVersion": "authentication.k8s.io/v1","kind": "SelfSubjectReview"} \
     https://cp.qvm0.lan:6443/apis/authentication.k8s.io/v1/selfsubjectreviews
#+end_example

Output snippet:
#+begin_src yaml
status:
userInfo:
  username: kwentine
  groups:
    - kwentine
    - system:authenticated
#+end_src

RBAC =ClusterRole= and =ClusterRoleBinding= allowing user =kwentine= to view pods are in [[file:rbac/]].
Verify that =kwentine= can indeed view pods:
#+begin_example
./kurl.sh pods
#+end_example

** Service account token

* Kubernetes HTTP API
The script =kurl.sh= explores the HTTP API exposed by the API server.
I am curious to understand how =kubectl= concepts map to the HTTP protocol.
* DNS
- I installed the CoreDNS Helm chart with default values, in the coredns =namespace=
- Initially, the Core DNS pod could not contact the API server
#+begin_example
[ERROR] plugin/kubernetes: Failed to watch
#+end_example
- The =kubernetes= service cluster IP was not included in the API server's certificate IPs.
  - I looked at the TLS config from "Kubernetes the hard way", and adjusted =--service-cluster-ip-range= accordingly.
    See: https://github.com/kelseyhightower/kubernetes-the-hard-way/issues/905
- Configure =kubelet=
  - =clusterDomain= should match the CoreDNS zone, =cluster.local= by default.
  - =clusterDNS= should match the =coredns= service =ClusterIP=

A good way to troubleshoot initial TLS error, since the CoreDNS logs are very terse:
#+begin_src sh
  kubectl run -n coredns debug-dns \
    --image=curlimages/curl:latest \
    --restart=Never \
    --command -- sleep 3600

  kubectl exec -n coredns debug-dns -- /bin/sh -c '
    CACERT=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)
    curl -v --cacert $CACERT -H "Authorization: Bearer $TOKEN" https://${KUBERNETES_SERVICE_HOST}:${KUBERNETES_SERVICE_PORT_HTTPS}/api/v1/endpoints
  '
#+end_src
See: [[https://kubernetes.io/docs/tasks/run-application/access-api-from-pod/][Accessing API server from pods]]

Another technique to check that the service account permissions are in order:
#+begin_example
$ kubectl --as system:serviceaccount:coredns:default auth can-i watch endpoints
yes
#+end_example

I took a long time to narrow down the issue and fix it, but it was instructive!
